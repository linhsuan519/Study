{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgu1r3i6IiYt/ES+8kIaeQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linhsuan519/hello-colab/blob/main/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#線性迴歸 (Linear Regression)\n",
        "\n",
        "* 一個簡單但常用的監督式學習算法，用於預測一個連續型變數的值。"
      ],
      "metadata": {
        "id": "skMRXK0jzAd-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QsWQ-XRcytjA"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 載入 Boston 房價數據集\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]\n",
        "X, y = data, target\n",
        "\n",
        "# 切分訓練集和測試集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 創建線性回歸模型\n",
        "model = LinearRegression()\n",
        "\n",
        "# 訓練模型\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 使用模型進行預測\n",
        "y_pred = model.predict(X_test)\n",
        "display(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "qR9t9y2dzm6e",
        "outputId": "29c97905-497e-4f1f-a6bf-98b71655b1a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([28.64896005, 36.49501384, 15.4111932 , 25.40321303, 18.85527988,\n",
              "       23.14668944, 17.3921241 , 14.07859899, 23.03692679, 20.59943345,\n",
              "       24.82286159, 18.53057049, -6.86543527, 21.80172334, 19.22571177,\n",
              "       26.19191985, 20.27733882,  5.61596432, 40.44887974, 17.57695918,\n",
              "       27.44319095, 30.1715964 , 10.94055823, 24.02083139, 18.07693812,\n",
              "       15.934748  , 23.12614028, 14.56052142, 22.33482544, 19.3257627 ,\n",
              "       22.16564973, 25.19476081, 25.31372473, 18.51345025, 16.6223286 ,\n",
              "       17.50268505, 30.94992991, 20.19201752, 23.90440431, 24.86975466,\n",
              "       13.93767876, 31.82504715, 42.56978796, 17.62323805, 27.01963242,\n",
              "       17.19006621, 13.80594006, 26.10356557, 20.31516118, 30.08649576,\n",
              "       21.3124053 , 34.15739602, 15.60444981, 26.11247588, 39.31613646,\n",
              "       22.99282065, 18.95764781, 33.05555669, 24.85114223, 12.91729352,\n",
              "       22.68101452, 30.80336295, 31.63522027, 16.29833689, 21.07379993,\n",
              "       16.57699669, 20.36362023, 26.15615896, 31.06833034, 11.98679953,\n",
              "       20.42550472, 27.55676301, 10.94316981, 16.82660609, 23.92909733,\n",
              "        5.28065815, 21.43504661, 41.33684993, 18.22211675,  9.48269245,\n",
              "       21.19857446, 12.95001331, 21.64822797,  9.3845568 , 23.06060014,\n",
              "       31.95762512, 19.16662892, 25.59942257, 29.35043558, 20.13138581,\n",
              "       25.57297369,  5.42970803, 20.23169356, 15.1949595 , 14.03241742,\n",
              "       20.91078077, 24.82249135, -0.47712079, 13.70520524, 15.69525576,\n",
              "       22.06972676, 24.64152943, 10.7382866 , 19.68622564, 23.63678009,\n",
              "       12.07974981, 18.47894211, 25.52713393, 20.93461307, 24.6955941 ,\n",
              "        7.59054562, 19.01046053, 21.9444339 , 27.22319977, 32.18608828,\n",
              "       15.27826455, 34.39190421, 12.96314168, 21.01681316, 28.57880911,\n",
              "       15.86300844, 24.85124135,  3.37937111, 23.90465773, 25.81792146,\n",
              "       23.11020547, 25.33489201, 33.35545176, 20.60724498, 38.4772665 ,\n",
              "       13.97398533, 25.21923987, 17.80946626, 20.63437371,  9.80267398,\n",
              "       21.07953576, 22.3378417 , 32.32381854, 31.48694863, 15.46621287,\n",
              "       16.86242766, 28.99330526, 24.95467894, 16.73633557,  6.12858395,\n",
              "       26.65990044, 23.34007187, 17.40367164, 13.38594123, 39.98342478,\n",
              "       16.68286302, 18.28561759])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 決策樹 (Decision Tree)\n",
        "\n",
        "\n",
        "* 一種樹狀模型，可以用於分類和回歸問題\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sgWM6hDe0JZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "bQU_0pja0Myq",
        "outputId": "480e7072-6bce-456a-8c8e-71d357db2b6d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4c8c3717fcb4>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m\"multilabel-sequences\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     ]:\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#載入 iris 房價數據集分類問題範例：\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 分類問題範例\n",
        "# 載入 iris 數據集\n",
        "data = load_iris()\n",
        "\n",
        "# 切分訓練集和測試集\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)\n",
        "\n",
        "# 創建分類樹模型\n",
        "clf_model = DecisionTreeClassifier()\n",
        "\n",
        "# 訓練模型\n",
        "clf_model.fit(X_train, y_train)\n",
        "\n",
        "# 使用模型進行預測\n",
        "y_pred_clf = clf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "vqn1W3aZ0f3p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#載入 Boston 房價數據集回歸問題範例：\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "# 回歸問題範例\n",
        "# 載入 Boston 房價數據集\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]\n",
        "X, y = data, target\n",
        "\n",
        "\n",
        "# 切分訓練集和測試集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "# 創建回歸樹模型\n",
        "reg_model = DecisionTreeRegressor()\n",
        "\n",
        "# 訓練模型\n",
        "reg_model.fit(X_train, y_train)\n",
        "\n",
        "# 使用模型進行預測\n",
        "y_pred_reg = reg_model.predict(X_test)"
      ],
      "metadata": {
        "id": "z5HR0B6K0nuA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#隨機森林 (Random Forest)\n",
        "\n",
        "*  一種集成學習方法，將多個決策樹組合在一起，通過投票或平均等方式來做出最終預測。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UWAFyeuh01qM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "Fvj7Bj7M0-Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#接下來以自定義的 iris 資料集轉換成 dataframe 示範 RandomForestRegressor：\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# 分類問題範例\n",
        "# 創建 iris 自定義資料集\n",
        "iris_data = {\n",
        "    'sepal_length': [5.1, 4.9, 4.7, 4.6, 5.0, 6.2, 6.4, 6.0, 6.9, 6.3, 5.8, 5.4, 5.6, 5.1, 5.7],\n",
        "    'sepal_width': [3.5, 3.0, 3.2, 3.1, 3.6, 2.9, 2.8, 3.0, 3.1, 2.5, 2.8, 3.0, 2.7, 3.8, 2.8],\n",
        "    'petal_length': [1.4, 1.4, 1.3, 1.5, 1.4, 4.3, 5.6, 4.8, 5.1, 5.0, 4.0, 4.5, 4.2, 1.6, 4.5],\n",
        "    'petal_width': [0.2, 0.2, 0.2, 0.2, 0.2, 1.3, 2.2, 1.8, 2.3, 1.9, 1.2, 1.5, 1.3, 0.2, 1.3],\n",
        "    'species': ['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor']\n",
        "}\n",
        "\n",
        "# 轉換為 dataframe\n",
        "iris_df = pd.DataFrame(iris_data)\n",
        "\n",
        "# 將類別變量轉換為數值變量\n",
        "iris_df['species'] = pd.factorize(iris_df['species'])[0]\n",
        "\n",
        "# 分割資料為訓練集與測試集\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_df.drop(columns=['sepal_length']), iris_df['sepal_length'], test_size=0.3, random_state=42)\n",
        "\n",
        "# 創建分類森林模型\n",
        "reg_model = RandomForestRegressor()\n",
        "\n",
        "# 訓練模型\n",
        "reg_model.fit(X_train, y_train)\n",
        "\n",
        "# 使用模型進行預測\n",
        "y_pred_reg = reg_model.predict(X_test)\n",
        "y_pred_reg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stj-hNr11CR_",
        "outputId": "aa71ff40-3250-438d-c258-953bc9270d5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.161, 5.705, 4.946, 5.117, 5.745])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#接下來以自定義的 iris 資料集轉換成 dataframe 示範 RandomForestClassifier：\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 分類問題範例\n",
        "# 創建 iris 自定義資料集\n",
        "iris_data = {\n",
        "    'sepal_length': [5.1, 4.9, 4.7, 4.6, 5.0, 6.2, 6.4, 6.0, 6.9, 6.3, 5.8, 5.4, 5.6, 5.1, 5.7],\n",
        "    'sepal_width': [3.5, 3.0, 3.2, 3.1, 3.6, 2.9, 2.8, 3.0, 3.1, 2.5, 2.8, 3.0, 2.7, 3.8, 2.8],\n",
        "    'petal_length': [1.4, 1.4, 1.3, 1.5, 1.4, 4.3, 5.6, 4.8, 5.1, 5.0, 4.0, 4.5, 4.2, 1.6, 4.5],\n",
        "    'petal_width': [0.2, 0.2, 0.2, 0.2, 0.2, 1.3, 2.2, 1.8, 2.3, 1.9, 1.2, 1.5, 1.3, 0.2, 1.3],\n",
        "    'species': ['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor']\n",
        "}\n",
        "\n",
        "# 轉換為 dataframe\n",
        "iris_df = pd.DataFrame(iris_data)\n",
        "\n",
        "# 分割資料為訓練集與測試集\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_df.drop(columns=['species']), iris_df['species'], test_size=0.3, random_state=42)\n",
        "\n",
        "# 創建分類森林模型\n",
        "clf_model = RandomForestClassifier()\n",
        "\n",
        "# 訓練模型\n",
        "clf_model.fit(X_train, y_train)\n",
        "\n",
        "# 使用模型進行預測\n",
        "y_pred_clf = clf_model.predict(X_test)\n",
        "y_pred_clf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_MJsUyB1JiY",
        "outputId": "ebc50a09-5d20-4ae1-f785-3880092a13dd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['virginica', 'versicolor', 'setosa', 'setosa', 'versicolor'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#支持向量機 (Support Vector Machine)\n",
        "\n",
        "* 一種二元分類和回歸分析的機器學習方法，通過將資料映射到高維空間，尋找超平面來分類或回歸。\n",
        "\n"
      ],
      "metadata": {
        "id": "PTH-4FDs_Tfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC, SVR\n",
        "\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "model = SVR()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "H4KZtmtG_X18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#一個自定義的範例資料示範 SVM 分類與回歸模型的使用：\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 自定義範例資料\n",
        "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]])\n",
        "y_classification = np.array([0, 0, 0, 1, 1, 1])\n",
        "y_regression = np.array([1, 2, 3, 4, 5, 6])\n",
        "\n",
        "# 切分訓練集與測試集\n",
        "X_train, X_test, y_train_classification, y_test_classification, y_train_regression, y_test_regression = train_test_split(\n",
        "    X, y_classification, y_regression, test_size=0.2, random_state=42)\n",
        "\n",
        "# 使用 SVM 分類器進行分類\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train_classification)\n",
        "y_pred_classification = model.predict(X_test)\n",
        "\n",
        "# 使用 SVM 迴歸器進行回歸\n",
        "model = SVR()\n",
        "model.fit(X_train, y_train_regression)\n",
        "y_pred_regression = model.predict(X_test)\n",
        "#y_classification 為一個包含了六個元素的陣列，代表了 X 中每個樣本的分類標籤，0 表示負類，1 表示正類\n",
        "#y_regression 為一個包含了六個元素的陣列，代表了 X 中每個樣本的回歸標籤。"
      ],
      "metadata": {
        "id": "xeyw5TZU_f4A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#K-Means 聚類 (K-Means Clustering)\n",
        "\n",
        "*   常用的非監督式學習算法，用於將資料分為 k 個不同的群體。\n",
        "\n"
      ],
      "metadata": {
        "id": "OvmjPnVpAWRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "model = KMeans(n_clusters=3)  #n_clusters 是要分類的群體數量\n",
        "model.fit(X_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "5oxFkqaKBSdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6jIugECDBatx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新增區段主成分分析 (Principal Component Analysis, PCA)\n",
        "\n",
        "*  一種降維算法，通過將高維資料映射到低維空間，保留最重要的特徵來簡化資料。\n",
        "\n"
      ],
      "metadata": {
        "id": "uRuQ-r7xBqVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "model = PCA(n_components=2)  #n_components 是要降維到的維度數量。\n",
        "X_train_pca = model.fit_transform(X_train)\n",
        "X_test_pca = model.transform(X_test)"
      ],
      "metadata": {
        "id": "IRtfJU2VBwsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#利用PCA降維，將高維度的資料轉換為二維或更低維度的資料：\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# 讀取手寫數字資料集\n",
        "digits = load_digits()\n",
        "\n",
        "# 將特徵與標籤拆開\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "\n",
        "# 切分資料集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 建立PCA模型，將64維的特徵轉換為2維\n",
        "model = PCA(n_components=2)\n",
        "X_train_pca = model.fit_transform(X_train)\n",
        "X_test_pca = model.transform(X_test)\n",
        "\n",
        "# 顯示轉換後的訓練集資料\n",
        "df = pd.DataFrame(data=X_train_pca, columns=['PC1', 'PC2'])\n",
        "df['target'] = y_train\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIRN_L8vBxIx",
        "outputId": "1dd371f2-78af-4894-d66e-0f3e5434d6f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         PC1        PC2  target\n",
            "0  16.468294  19.392479       6\n",
            "1  -3.066055  22.375259       0\n",
            "2  13.134392  20.354296       0\n",
            "3 -22.619748  -5.528616       3\n",
            "4  -2.003766  23.617260       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#利用 PyTorch 實作深度學習模型\n",
        "\n",
        "step1.  準備資料集\n",
        "\n",
        "step2.  數據預處理  (特徵縮放、類別特徵編碼、缺失值處理)\n",
        "\n",
        "step3.   設計深度學習模型 ( torch.nn 模組 MLP)\n",
        "\n",
        "step4.   訓練模型\n",
        "\n",
        "step5.   評估模型\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VXZpU1KaCJzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#步驟 1：準備資料集\n",
        "\n",
        "#首先，我們需要準備波士頓房價預測的資料集。我們將使用 scikit-learn 內建的波士頓房價資料集。\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 載入波士頓房價資料集\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "features = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 切割資料集為訓練集和測試集\n",
        "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2)\n",
        "步驟 2：數據預處理\n",
        "\n",
        "在訓練模型之前，我們需要對資料進行預處理。這可能包括特徵縮放、類別特徵編碼、缺失值處理等。您可以使用 Python 的資料處理庫（如 scikit-learn）來執行這些預處理步驟。\n",
        "\n",
        "步驟 3：設計深度學習模型\n",
        "\n",
        "現在我們開始設計深度學習模型。使用 PyTorch，我們可以使用它的 torch.nn 模組來構建模型。以下是一個簡單的多層感知機（MLP）範例：\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 定義自定義模型\n",
        "class HousePricePredictor(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(HousePricePredictor, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "步驟 4：訓練模型\n",
        "\n",
        "現在我們已經準備好資料集並設計了模型，接下來是訓練模型。我們將使用 PyTorch 的優化器和損失函數來訓練模型。以下是一個簡單的訓練過程：\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# 定義設備\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 創建模型實例\n",
        "model = HousePricePredictor(input_size=13).to(device)\n",
        "\n",
        "# 定義損失函數和優化器\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 設定訓練迴圈\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # 將特徵和目標轉換為 Tensor\n",
        "    features_tensor = torch.Tensor(features).to(device)\n",
        "    target_tensor = torch.Tensor(target).unsqueeze(1).to(device)\n",
        "\n",
        "    # 正向傳播\n",
        "    outputs = model(features_tensor)\n",
        "    loss = criterion(outputs, target_tensor)\n",
        "\n",
        "    # 反向傳播和參數更新\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 每隔 10 個迭代顯示一次損失\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
        "步驟 5：評估模型\n",
        "\n",
        "完成訓練後，我們可以使用測試集來評估模型的性能。以下是一個簡單的評估過程：\n",
        "\n",
        "# 將特徵轉換為 Tensor\n",
        "test_features_tensor = torch.Tensor(test_features).to(device)\n",
        "\n",
        "# 預測房價\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    predictions = model(test_features_tensor)\n",
        "\n",
        "# 轉換為 NumPy 陣列\n",
        "predictions = predictions.cpu().numpy()\n",
        "\n",
        "# 計算評估指標（例如均方根誤差）\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mse = mean_squared_error(test_target, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
        "這樣就完成了使用 PyTorch 進行房價預測的教學，可以根據需要進行進一步的模型調整和優化。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "f2ONhbknCLO9",
        "outputId": "eb90a734-041f-4835-9e80-556922d36a67"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-bb207fbb4b88>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    步驟 1：準備資料集\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ]
    }
  ]
}