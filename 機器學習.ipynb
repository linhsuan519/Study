{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0pY7Sn7gMubgiXM7rL8Dh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linhsuan519/hello-colab/blob/main/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#線性迴歸 (Linear Regression)\n",
        "\n",
        "* 一個簡單但常用的監督式學習算法，用於預測一個連續型變數的值。"
      ],
      "metadata": {
        "id": "skMRXK0jzAd-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QsWQ-XRcytjA"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 載入 Boston 房價數據集\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]\n",
        "X, y = data, target\n",
        "\n",
        "# 切分訓練集和測試集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 創建線性回歸模型\n",
        "model = LinearRegression()\n",
        "\n",
        "# 訓練模型\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 使用模型進行預測\n",
        "y_pred = model.predict(X_test)\n",
        "display(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "qR9t9y2dzm6e",
        "outputId": "29c97905-497e-4f1f-a6bf-98b71655b1a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([28.64896005, 36.49501384, 15.4111932 , 25.40321303, 18.85527988,\n",
              "       23.14668944, 17.3921241 , 14.07859899, 23.03692679, 20.59943345,\n",
              "       24.82286159, 18.53057049, -6.86543527, 21.80172334, 19.22571177,\n",
              "       26.19191985, 20.27733882,  5.61596432, 40.44887974, 17.57695918,\n",
              "       27.44319095, 30.1715964 , 10.94055823, 24.02083139, 18.07693812,\n",
              "       15.934748  , 23.12614028, 14.56052142, 22.33482544, 19.3257627 ,\n",
              "       22.16564973, 25.19476081, 25.31372473, 18.51345025, 16.6223286 ,\n",
              "       17.50268505, 30.94992991, 20.19201752, 23.90440431, 24.86975466,\n",
              "       13.93767876, 31.82504715, 42.56978796, 17.62323805, 27.01963242,\n",
              "       17.19006621, 13.80594006, 26.10356557, 20.31516118, 30.08649576,\n",
              "       21.3124053 , 34.15739602, 15.60444981, 26.11247588, 39.31613646,\n",
              "       22.99282065, 18.95764781, 33.05555669, 24.85114223, 12.91729352,\n",
              "       22.68101452, 30.80336295, 31.63522027, 16.29833689, 21.07379993,\n",
              "       16.57699669, 20.36362023, 26.15615896, 31.06833034, 11.98679953,\n",
              "       20.42550472, 27.55676301, 10.94316981, 16.82660609, 23.92909733,\n",
              "        5.28065815, 21.43504661, 41.33684993, 18.22211675,  9.48269245,\n",
              "       21.19857446, 12.95001331, 21.64822797,  9.3845568 , 23.06060014,\n",
              "       31.95762512, 19.16662892, 25.59942257, 29.35043558, 20.13138581,\n",
              "       25.57297369,  5.42970803, 20.23169356, 15.1949595 , 14.03241742,\n",
              "       20.91078077, 24.82249135, -0.47712079, 13.70520524, 15.69525576,\n",
              "       22.06972676, 24.64152943, 10.7382866 , 19.68622564, 23.63678009,\n",
              "       12.07974981, 18.47894211, 25.52713393, 20.93461307, 24.6955941 ,\n",
              "        7.59054562, 19.01046053, 21.9444339 , 27.22319977, 32.18608828,\n",
              "       15.27826455, 34.39190421, 12.96314168, 21.01681316, 28.57880911,\n",
              "       15.86300844, 24.85124135,  3.37937111, 23.90465773, 25.81792146,\n",
              "       23.11020547, 25.33489201, 33.35545176, 20.60724498, 38.4772665 ,\n",
              "       13.97398533, 25.21923987, 17.80946626, 20.63437371,  9.80267398,\n",
              "       21.07953576, 22.3378417 , 32.32381854, 31.48694863, 15.46621287,\n",
              "       16.86242766, 28.99330526, 24.95467894, 16.73633557,  6.12858395,\n",
              "       26.65990044, 23.34007187, 17.40367164, 13.38594123, 39.98342478,\n",
              "       16.68286302, 18.28561759])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 決策樹 (Decision Tree)\n",
        "\n",
        "\n",
        "* 一種樹狀模型，可以用於分類和回歸問題\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sgWM6hDe0JZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "bQU_0pja0Myq",
        "outputId": "480e7072-6bce-456a-8c8e-71d357db2b6d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4c8c3717fcb4>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m\"multilabel-sequences\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     ]:\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#載入 iris 房價數據集分類問題範例：\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 分類問題範例\n",
        "# 載入 iris 數據集\n",
        "data = load_iris()\n",
        "\n",
        "# 切分訓練集和測試集\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)\n",
        "\n",
        "# 創建分類樹模型\n",
        "clf_model = DecisionTreeClassifier()\n",
        "\n",
        "# 訓練模型\n",
        "clf_model.fit(X_train, y_train)\n",
        "\n",
        "# 使用模型進行預測\n",
        "y_pred_clf = clf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "vqn1W3aZ0f3p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#載入 Boston 房價數據集回歸問題範例：\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "# 回歸問題範例\n",
        "# 載入 Boston 房價數據集\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]\n",
        "X, y = data, target\n",
        "\n",
        "\n",
        "# 切分訓練集和測試集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "# 創建回歸樹模型\n",
        "reg_model = DecisionTreeRegressor()\n",
        "\n",
        "# 訓練模型\n",
        "reg_model.fit(X_train, y_train)\n",
        "\n",
        "# 使用模型進行預測\n",
        "y_pred_reg = reg_model.predict(X_test)"
      ],
      "metadata": {
        "id": "z5HR0B6K0nuA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#隨機森林 (Random Forest)\n",
        "\n",
        "*  一種集成學習方法，將多個決策樹組合在一起，通過投票或平均等方式來做出最終預測。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UWAFyeuh01qM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "Fvj7Bj7M0-Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#接下來以自定義的 iris 資料集轉換成 dataframe 示範 RandomForestRegressor：\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# 分類問題範例\n",
        "# 創建 iris 自定義資料集\n",
        "iris_data = {\n",
        "    'sepal_length': [5.1, 4.9, 4.7, 4.6, 5.0, 6.2, 6.4, 6.0, 6.9, 6.3, 5.8, 5.4, 5.6, 5.1, 5.7],\n",
        "    'sepal_width': [3.5, 3.0, 3.2, 3.1, 3.6, 2.9, 2.8, 3.0, 3.1, 2.5, 2.8, 3.0, 2.7, 3.8, 2.8],\n",
        "    'petal_length': [1.4, 1.4, 1.3, 1.5, 1.4, 4.3, 5.6, 4.8, 5.1, 5.0, 4.0, 4.5, 4.2, 1.6, 4.5],\n",
        "    'petal_width': [0.2, 0.2, 0.2, 0.2, 0.2, 1.3, 2.2, 1.8, 2.3, 1.9, 1.2, 1.5, 1.3, 0.2, 1.3],\n",
        "    'species': ['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor']\n",
        "}\n",
        "\n",
        "# 轉換為 dataframe\n",
        "iris_df = pd.DataFrame(iris_data)\n",
        "\n",
        "# 將類別變量轉換為數值變量\n",
        "iris_df['species'] = pd.factorize(iris_df['species'])[0]\n",
        "\n",
        "# 分割資料為訓練集與測試集\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_df.drop(columns=['sepal_length']), iris_df['sepal_length'], test_size=0.3, random_state=42)\n",
        "\n",
        "# 創建分類森林模型\n",
        "reg_model = RandomForestRegressor()\n",
        "\n",
        "# 訓練模型\n",
        "reg_model.fit(X_train, y_train)\n",
        "\n",
        "# 使用模型進行預測\n",
        "y_pred_reg = reg_model.predict(X_test)\n",
        "y_pred_reg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stj-hNr11CR_",
        "outputId": "aa71ff40-3250-438d-c258-953bc9270d5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.161, 5.705, 4.946, 5.117, 5.745])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#接下來以自定義的 iris 資料集轉換成 dataframe 示範 RandomForestClassifier：\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 分類問題範例\n",
        "# 創建 iris 自定義資料集\n",
        "iris_data = {\n",
        "    'sepal_length': [5.1, 4.9, 4.7, 4.6, 5.0, 6.2, 6.4, 6.0, 6.9, 6.3, 5.8, 5.4, 5.6, 5.1, 5.7],\n",
        "    'sepal_width': [3.5, 3.0, 3.2, 3.1, 3.6, 2.9, 2.8, 3.0, 3.1, 2.5, 2.8, 3.0, 2.7, 3.8, 2.8],\n",
        "    'petal_length': [1.4, 1.4, 1.3, 1.5, 1.4, 4.3, 5.6, 4.8, 5.1, 5.0, 4.0, 4.5, 4.2, 1.6, 4.5],\n",
        "    'petal_width': [0.2, 0.2, 0.2, 0.2, 0.2, 1.3, 2.2, 1.8, 2.3, 1.9, 1.2, 1.5, 1.3, 0.2, 1.3],\n",
        "    'species': ['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor']\n",
        "}\n",
        "\n",
        "# 轉換為 dataframe\n",
        "iris_df = pd.DataFrame(iris_data)\n",
        "\n",
        "# 分割資料為訓練集與測試集\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_df.drop(columns=['species']), iris_df['species'], test_size=0.3, random_state=42)\n",
        "\n",
        "# 創建分類森林模型\n",
        "clf_model = RandomForestClassifier()\n",
        "\n",
        "# 訓練模型\n",
        "clf_model.fit(X_train, y_train)\n",
        "\n",
        "# 使用模型進行預測\n",
        "y_pred_clf = clf_model.predict(X_test)\n",
        "y_pred_clf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_MJsUyB1JiY",
        "outputId": "ebc50a09-5d20-4ae1-f785-3880092a13dd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['virginica', 'versicolor', 'setosa', 'setosa', 'versicolor'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#支持向量機 (Support Vector Machine)\n",
        "\n",
        "* 一種二元分類和回歸分析的機器學習方法，通過將資料映射到高維空間，尋找超平面來分類或回歸。\n",
        "\n"
      ],
      "metadata": {
        "id": "PTH-4FDs_Tfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC, SVR\n",
        "\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "model = SVR()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "H4KZtmtG_X18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#一個自定義的範例資料示範 SVM 分類與回歸模型的使用：\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 自定義範例資料\n",
        "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]])\n",
        "y_classification = np.array([0, 0, 0, 1, 1, 1])\n",
        "y_regression = np.array([1, 2, 3, 4, 5, 6])\n",
        "\n",
        "# 切分訓練集與測試集\n",
        "X_train, X_test, y_train_classification, y_test_classification, y_train_regression, y_test_regression = train_test_split(\n",
        "    X, y_classification, y_regression, test_size=0.2, random_state=42)\n",
        "\n",
        "# 使用 SVM 分類器進行分類\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train_classification)\n",
        "y_pred_classification = model.predict(X_test)\n",
        "\n",
        "# 使用 SVM 迴歸器進行回歸\n",
        "model = SVR()\n",
        "model.fit(X_train, y_train_regression)\n",
        "y_pred_regression = model.predict(X_test)\n",
        "#y_classification 為一個包含了六個元素的陣列，代表了 X 中每個樣本的分類標籤，0 表示負類，1 表示正類\n",
        "#y_regression 為一個包含了六個元素的陣列，代表了 X 中每個樣本的回歸標籤。"
      ],
      "metadata": {
        "id": "xeyw5TZU_f4A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#K-Means 聚類 (K-Means Clustering)"
      ],
      "metadata": {
        "id": "OvmjPnVpAWRI"
      }
    }
  ]
}